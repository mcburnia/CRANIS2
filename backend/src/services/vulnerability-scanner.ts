import pool from '../db/pool.js';
import { getDriver } from '../db/neo4j.js';
import { decrypt } from '../utils/encryption.js';
import { createNotification } from './notifications.js';

interface Dependency {
  name: string;
  version: string;
  purl: string;
  ecosystem: string;
  license: string;
}

interface VulnFinding {
  source: string;
  sourceId: string;
  severity: string;
  cvssScore: number | null;
  title: string;
  description: string;
  dependencyName: string;
  dependencyVersion: string;
  dependencyEcosystem: string;
  dependencyPurl: string;
  affectedVersions: string;
  fixedVersion: string;
  referencesUrl: string;
  mitigation: string;
}

interface ProductRef {
  productId: string;
  orgId: string;
  productName: string;
}

// --- Mitigation guidance generator ---
function generateMitigation(finding: Partial<VulnFinding>): string {
  const parts: string[] = [];

  // Primary action: upgrade if fix available
  if (finding.fixedVersion) {
    parts.push('Upgrade ' + finding.dependencyName + ' from ' + finding.dependencyVersion + ' to ' + finding.fixedVersion + ' or later.');
  } else {
    parts.push('Check for a patched version of ' + finding.dependencyName + ' (current: ' + finding.dependencyVersion + ').');
  }

  // Severity-based urgency
  if (finding.severity === 'critical') {
    parts.push('CRITICAL: This vulnerability requires immediate remediation. Consider blocking deployment until resolved.');
  } else if (finding.severity === 'high') {
    parts.push('HIGH priority: Schedule remediation within the current sprint or release cycle.');
  } else if (finding.severity === 'medium') {
    parts.push('MEDIUM priority: Plan remediation in an upcoming release.');
  } else {
    parts.push('LOW priority: Address when convenient or during routine maintenance.');
  }

  // If no fix exists, suggest alternatives
  if (!finding.fixedVersion) {
    parts.push('If no patch is available: evaluate whether the vulnerable functionality is used in your application. Consider alternative packages or applying a workaround.');
  }

  // CRA-specific guidance
  parts.push('CRA Art. 13(6): Document this vulnerability and remediation steps in your vulnerability handling process.');

  return parts.join(' ');
}

// --- OSV.dev batch query ---
async function scanOSV(dependencies: Dependency[]): Promise<VulnFinding[]> {
  const findings: VulnFinding[] = [];

  const validDeps = dependencies.filter(d => d.purl && d.purl.startsWith('pkg:'));
  if (validDeps.length === 0) return findings;

  const batchSize = 1000;
  for (let i = 0; i < validDeps.length; i += batchSize) {
    const batch = validDeps.slice(i, i + batchSize);
    const queries = batch.map(d => ({ package: { purl: d.purl } }));

    try {
      const resp = await fetch('https://api.osv.dev/v1/querybatch', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ queries }),
      });

      if (!resp.ok) {
        console.error('[VULN-SCAN] OSV batch query failed: ' + resp.status);
        continue;
      }

      const data = await resp.json() as { results: Array<{ vulns?: Array<any> }> };

      for (let j = 0; j < data.results.length; j++) {
        const result = data.results[j];
        const dep = batch[j];
        if (!result.vulns || result.vulns.length === 0) continue;

        for (const vuln of result.vulns) {
          const severity = mapOSVSeverity(vuln);
          const cvss = extractOSVCVSSScore(vuln);
          const cveId = vuln.aliases?.find((a: string) => a.startsWith('CVE-')) || vuln.id;
          const fixedVer = extractFixedVersion(vuln, dep.ecosystem);
          const refs = (vuln.references || []).map((r: any) => r.url).filter(Boolean);
          const uniqueRefs = [...new Set(refs)].join(', ');

          const finding: VulnFinding = {
            source: 'osv',
            sourceId: cveId || vuln.id,
            severity,
            cvssScore: cvss,
            title: vuln.summary || cveId || vuln.id,
            description: (vuln.details || '').substring(0, 2000),
            dependencyName: dep.name,
            dependencyVersion: dep.version,
            dependencyEcosystem: dep.ecosystem,
            dependencyPurl: dep.purl,
            affectedVersions: formatAffectedVersions(vuln),
            fixedVersion: fixedVer,
            referencesUrl: uniqueRefs,
            mitigation: '',
          };
          finding.mitigation = generateMitigation(finding);
          findings.push(finding);
        }
      }
    } catch (err) {
      console.error('[VULN-SCAN] OSV query error:', err);
    }
  }

  return findings;
}

// --- GitHub Advisory Database ---
async function scanGitHub(dependencies: Dependency[], githubToken: string | null): Promise<VulnFinding[]> {
  const findings: VulnFinding[] = [];
  if (!githubToken) {
    console.log('[VULN-SCAN] No GitHub token available, skipping GitHub advisory scan');
    return findings;
  }

  const ecosystemMap: Record<string, string> = {
    'npm': 'npm', 'pip': 'pip', 'maven': 'maven', 'nuget': 'nuget',
    'rubygems': 'rubygems', 'go': 'go', 'rust': 'crates.io', 'composer': 'composer',
  };

  // Build lookup of our dependency names
  const depsByEcosystem: Record<string, Map<string, Dependency>> = {};
  for (const dep of dependencies) {
    const ghEco = ecosystemMap[dep.ecosystem?.toLowerCase()];
    if (!ghEco) continue;
    if (!depsByEcosystem[ghEco]) depsByEcosystem[ghEco] = new Map();
    depsByEcosystem[ghEco].set(dep.name.toLowerCase(), dep);
  }

  for (const [ecosystem, depMap] of Object.entries(depsByEcosystem)) {
    try {
      // Fetch advisories for this ecosystem
      const url = 'https://api.github.com/advisories?ecosystem=' + ecosystem + '&per_page=100';
      const resp = await fetch(url, {
        headers: {
          'Authorization': 'Bearer ' + githubToken,
          'Accept': 'application/vnd.github+json',
          'X-GitHub-Api-Version': '2022-11-28',
        },
      });

      if (!resp.ok) {
        console.error('[VULN-SCAN] GitHub advisory query failed for ' + ecosystem + ': ' + resp.status);
        continue;
      }

      const advisories = await resp.json() as Array<any>;

      for (const advisory of advisories) {
        if (!advisory.vulnerabilities) continue;

        for (const vuln of advisory.vulnerabilities) {
          const pkgName = vuln.package?.name?.toLowerCase();
          if (!pkgName) continue;

          const matchedDep = depMap.get(pkgName);
          if (!matchedDep) continue;

          const cveId = advisory.cve_id || advisory.ghsa_id;
          const patchedVersions = vuln.patched_versions || '';

          const finding: VulnFinding = {
            source: 'github',
            sourceId: cveId || advisory.ghsa_id,
            severity: (advisory.severity || 'medium').toLowerCase(),
            cvssScore: advisory.cvss?.score || null,
            title: advisory.summary || advisory.ghsa_id,
            description: (advisory.description || '').substring(0, 2000),
            dependencyName: matchedDep.name,
            dependencyVersion: matchedDep.version,
            dependencyEcosystem: matchedDep.ecosystem,
            dependencyPurl: matchedDep.purl,
            affectedVersions: vuln.vulnerable_version_range || '',
            fixedVersion: patchedVersions,
            referencesUrl: advisory.html_url || '',
            mitigation: '',
          };
          finding.mitigation = generateMitigation(finding);
          findings.push(finding);
        }
      }
    } catch (err) {
      console.error('[VULN-SCAN] GitHub advisory error for ' + ecosystem + ':', err);
    }
  }

  return findings;
}

// --- NVD (NIST) ---
async function scanNVD(dependencies: Dependency[], maxQueries: number = 50): Promise<VulnFinding[]> {
  const findings: VulnFinding[] = [];
  const delayMs = 6500;

  const toQuery = dependencies.slice(0, maxQueries);

  for (const dep of toQuery) {
    try {
      const searchName = dep.name.replace(/^@/, '').replace(/\//, ' ');
      const url = 'https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=' + encodeURIComponent(searchName) + '&resultsPerPage=5';

      const resp = await fetch(url, {
        headers: { 'Accept': 'application/json' },
      });

      if (resp.status === 403 || resp.status === 429) {
        console.log('[VULN-SCAN] NVD rate limit hit, stopping NVD queries');
        break;
      }

      if (!resp.ok) {
        console.error('[VULN-SCAN] NVD query failed for ' + dep.name + ': ' + resp.status);
        await sleep(delayMs);
        continue;
      }

      const data = await resp.json() as { vulnerabilities?: Array<any> };

      if (data.vulnerabilities) {
        for (const item of data.vulnerabilities) {
          const cve = item.cve;
          if (!cve) continue;

          const cvssData = cve.metrics?.cvssMetricV31?.[0]?.cvssData ||
                          cve.metrics?.cvssMetricV30?.[0]?.cvssData ||
                          cve.metrics?.cvssMetricV2?.[0]?.cvssData;

          const severity = cvssData?.baseSeverity?.toLowerCase() ||
                          mapCVSStoSeverity(cvssData?.baseScore);

          const description = cve.descriptions?.find((d: any) => d.lang === 'en')?.value || '';
          const refs = (cve.references || []).map((r: any) => r.url).filter(Boolean);
          const uniqueRefs = [...new Set(refs)].join(', ');

          // Try to extract fix version from references or description
          const fixedVersion = extractFixFromNVD(cve, dep.name);

          const finding: VulnFinding = {
            source: 'nvd',
            sourceId: cve.id,
            severity: severity || 'medium',
            cvssScore: cvssData?.baseScore || null,
            title: cve.id + ': ' + description.substring(0, 120),
            description: description.substring(0, 2000),
            dependencyName: dep.name,
            dependencyVersion: dep.version,
            dependencyEcosystem: dep.ecosystem,
            dependencyPurl: dep.purl,
            affectedVersions: extractNVDAffectedVersions(cve),
            fixedVersion,
            referencesUrl: uniqueRefs,
            mitigation: '',
          };
          finding.mitigation = generateMitigation(finding);
          findings.push(finding);
        }
      }

      await sleep(delayMs);
    } catch (err) {
      console.error('[VULN-SCAN] NVD error for ' + dep.name + ':', err);
    }
  }

  return findings;
}

// --- NVD-specific helpers ---
function extractFixFromNVD(cve: any, depName: string): string {
  // Look through references for release/tag URLs that suggest a fix
  const refs = (cve.references || []).map((r: any) => r.url || '');
  for (const ref of refs) {
    // Match GitHub release tag URLs like /releases/tag/v6.12.3
    const tagMatch = ref.match(/\/releases\/tag\/v?(\d+\.\d+\.\d+[\w.-]*)/);
    if (tagMatch) return tagMatch[1];
  }
  return '';
}

function extractNVDAffectedVersions(cve: any): string {
  const configs = cve.configurations || [];
  const versions: string[] = [];
  for (const config of configs) {
    for (const node of config.nodes || []) {
      for (const match of node.cpeMatch || []) {
        if (match.vulnerable) {
          const parts: string[] = [];
          if (match.versionStartIncluding) parts.push('>= ' + match.versionStartIncluding);
          if (match.versionEndExcluding) parts.push('< ' + match.versionEndExcluding);
          if (match.versionEndIncluding) parts.push('<= ' + match.versionEndIncluding);
          if (parts.length > 0) versions.push(parts.join(' '));
        }
      }
    }
  }
  return versions.join(' | ');
}

// --- Shared helpers ---
function mapOSVSeverity(vuln: any): string {
  const dbSeverity = vuln.database_specific?.severity;
  if (dbSeverity) return dbSeverity.toLowerCase();
  if (vuln.severity && vuln.severity.length > 0) {
    for (const s of vuln.severity) {
      if (s.type === 'CVSS_V3' && s.score) {
        const scoreMatch = s.score.match(/CVSS:3\.\d\/AV:\w\/AC:\w\/PR:\w\/UI:\w\/S:\w\/C:\w\/I:\w\/A:\w/);
        if (scoreMatch) {
          const numScore = extractCVSSNumericScore(s.score);
          if (numScore !== null) return mapCVSStoSeverity(numScore);
        }
      }
    }
  }
  return 'medium';
}

function extractOSVCVSSScore(vuln: any): number | null {
  if (vuln.severity && vuln.severity.length > 0) {
    for (const s of vuln.severity) {
      if (s.type === 'CVSS_V3' && s.score) {
        return extractCVSSNumericScore(s.score);
      }
    }
  }
  return null;
}

function extractCVSSNumericScore(vector: string): number | null {
  // CVSS v3 score calculation is complex — use a rough approximation
  // by counting impact metrics
  if (!vector.startsWith('CVSS:3')) return null;
  const parts = vector.split('/');
  let score = 0;
  for (const part of parts) {
    if (part.startsWith('AV:N')) score += 2;
    else if (part.startsWith('AV:A')) score += 1.5;
    if (part.startsWith('AC:L')) score += 1;
    if (part.startsWith('PR:N')) score += 1;
    if (part.startsWith('UI:N')) score += 0.5;
    if (part.startsWith('C:H')) score += 1.5;
    if (part.startsWith('I:H')) score += 1.5;
    if (part.startsWith('A:H')) score += 1.5;
  }
  return Math.min(Math.round(score * 10) / 10, 10.0);
}

function mapCVSStoSeverity(score: number | undefined | null): string {
  if (!score) return 'medium';
  if (score >= 9.0) return 'critical';
  if (score >= 7.0) return 'high';
  if (score >= 4.0) return 'medium';
  return 'low';
}

function extractFixedVersion(vuln: any, ecosystem: string): string {
  if (!vuln.affected) return '';
  for (const affected of vuln.affected) {
    if (affected.ranges) {
      for (const range of affected.ranges) {
        if (range.events) {
          const fixed = range.events.find((e: any) => e.fixed);
          if (fixed) return fixed.fixed;
        }
      }
    }
    // Also check versions array for 'SPECIFIC' range type
    if (affected.versions && affected.database_specific?.last_known_affected_version_range) {
      // Some OSV entries have this
    }
  }
  return '';
}

function formatAffectedVersions(vuln: any): string {
  if (!vuln.affected) return '';
  const ranges: string[] = [];
  for (const affected of vuln.affected) {
    if (affected.ranges) {
      for (const range of affected.ranges) {
        const parts: string[] = [];
        for (const event of range.events || []) {
          if (event.introduced) parts.push('>= ' + event.introduced);
          if (event.fixed) parts.push('< ' + event.fixed);
          if (event.last_affected) parts.push('<= ' + event.last_affected);
        }
        if (parts.length > 0) ranges.push(parts.join(', '));
      }
    }
  }
  return ranges.join(' | ');
}

function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}

function deduplicateFindings(findings: VulnFinding[]): VulnFinding[] {
  const seen = new Map<string, VulnFinding>();
  const sourcePriority: Record<string, number> = { 'github': 3, 'osv': 2, 'nvd': 1 };

  for (const finding of findings) {
    const key = finding.sourceId + ':' + finding.dependencyPurl;
    const existing = seen.get(key);

    if (!existing) {
      seen.set(key, finding);
    } else {
      // Merge: keep highest priority source but fill in missing data
      const priority = sourcePriority[finding.source] || 0;
      const existingPriority = sourcePriority[existing.source] || 0;

      if (priority > existingPriority) {
        // New source is higher priority — use it but fill gaps
        if (!finding.fixedVersion && existing.fixedVersion) finding.fixedVersion = existing.fixedVersion;
        if (!finding.affectedVersions && existing.affectedVersions) finding.affectedVersions = existing.affectedVersions;
        if (!finding.cvssScore && existing.cvssScore) finding.cvssScore = existing.cvssScore;
        finding.mitigation = generateMitigation(finding);
        seen.set(key, finding);
      } else {
        // Existing is higher priority — fill its gaps from new
        if (!existing.fixedVersion && finding.fixedVersion) existing.fixedVersion = finding.fixedVersion;
        if (!existing.affectedVersions && finding.affectedVersions) existing.affectedVersions = finding.affectedVersions;
        if (!existing.cvssScore && finding.cvssScore) existing.cvssScore = finding.cvssScore;
        existing.mitigation = generateMitigation(existing);
      }
    }
  }

  return Array.from(seen.values());
}

// =====================================================================
// Platform-wide vulnerability scan
// =====================================================================

export async function runPlatformScan(
  triggeredBy: string,
  triggerType: 'scheduled' | 'manual'
): Promise<{ runId: string; totalFindings: number }> {

  // 1. Create platform scan run record
  const runResult = await pool.query(
    "INSERT INTO platform_scan_runs (triggered_by, trigger_type, status) VALUES ($1, $2, 'running') RETURNING id",
    [triggeredBy, triggerType]
  );
  const runId = runResult.rows[0].id;
  const scanStartTime = Date.now();

  console.log('[PLATFORM-SCAN] Started run ' + runId + ' (triggered by: ' + triggeredBy + ', type: ' + triggerType + ')');

  try {
    // 2. Gather ALL dependencies across ALL products from Neo4j
    const neo4jSession = getDriver().session();
    const uniqueDeps = new Map<string, Dependency>();
    const purlToProducts = new Map<string, ProductRef[]>();
    const allProductIds = new Set<string>();

    try {
      const result = await neo4jSession.run(
        'MATCH (o:Organisation)<-[:BELONGS_TO]-(p:Product)-[:DEPENDS_ON]->(d:Dependency) ' +
        'RETURN o.id AS orgId, p.id AS productId, p.name AS productName, ' +
        'd.name AS depName, d.version AS depVersion, d.purl AS depPurl, ' +
        'd.ecosystem AS depEcosystem, d.license AS depLicense'
      );

      for (const record of result.records) {
        const purl = record.get('depPurl') || '';
        const productId = record.get('productId');
        const orgId = record.get('orgId');
        const productName = record.get('productName') || 'Unknown';

        if (!purl) continue;

        allProductIds.add(productId);

        // Deduplicated dependency list
        if (!uniqueDeps.has(purl)) {
          uniqueDeps.set(purl, {
            name: record.get('depName') || '',
            version: record.get('depVersion') || '',
            purl,
            ecosystem: record.get('depEcosystem') || '',
            license: record.get('depLicense') || '',
          });
        }

        // Map purl to products
        if (!purlToProducts.has(purl)) {
          purlToProducts.set(purl, []);
        }
        const existing = purlToProducts.get(purl)!;
        // Avoid duplicate product entries for the same purl
        if (!existing.some(p => p.productId === productId)) {
          existing.push({ productId, orgId, productName });
        }
      }
    } finally {
      await neo4jSession.close();
    }

    const depList = Array.from(uniqueDeps.values());
    const productCount = allProductIds.size;

    console.log('[PLATFORM-SCAN] Found ' + depList.length + ' unique dependencies across ' + productCount + ' products');

    // Update run with counts
    await pool.query(
      'UPDATE platform_scan_runs SET total_products = $2, total_unique_dependencies = $3 WHERE id = $1',
      [runId, productCount, depList.length]
    );

    if (depList.length === 0) {
      await pool.query(
        "UPDATE platform_scan_runs SET status = 'completed', completed_at = NOW(), duration_seconds = 0, total_findings = 0 WHERE id = $1",
        [runId]
      );
      console.log('[PLATFORM-SCAN] No dependencies to scan, completing');
      return { runId, totalFindings: 0 };
    }

    // 3. Get a GitHub token (first available from any org)
    let githubToken: string | null = null;
    try {
      const tokenResult = await pool.query(
        'SELECT gc.access_token_encrypted FROM github_connections gc LIMIT 1'
      );
      if (tokenResult.rows.length > 0) {
        githubToken = decrypt(tokenResult.rows[0].access_token_encrypted);
      }
    } catch (err) {
      console.error('[PLATFORM-SCAN] Could not get GitHub token:', err);
    }

    // 4. Run OSV + GitHub in parallel on the deduplicated list
    const osvStart = Date.now();
    const ghStart = Date.now();
    const [osvFindings, ghFindings] = await Promise.all([
      scanOSV(depList),
      scanGitHub(depList, githubToken),
    ]);
    const osvDurationMs = Date.now() - osvStart;
    const ghDurationMs = Date.now() - ghStart;

    console.log('[PLATFORM-SCAN] OSV: ' + osvFindings.length + ' findings in ' + osvDurationMs + 'ms, GitHub: ' + ghFindings.length + ' findings in ' + ghDurationMs + 'ms');

    // 5. NVD: prioritise deps with existing findings, then by product coverage
    const depsWithFindings = new Set([...osvFindings, ...ghFindings].map(f => f.dependencyPurl));
    const NVD_MAX = 50;

    // Priority 1: deps already known to have vulnerabilities
    const nvdPriority1 = depList.filter(d => depsWithFindings.has(d.purl));
    // Priority 2: deps used by most products
    const nvdPriority2 = depList
      .filter(d => !depsWithFindings.has(d.purl))
      .sort((a, b) => (purlToProducts.get(b.purl)?.length || 0) - (purlToProducts.get(a.purl)?.length || 0));

    const nvdCandidates = [...nvdPriority1, ...nvdPriority2].slice(0, NVD_MAX);

    const nvdStart = Date.now();
    const nvdFindings = await scanNVD(nvdCandidates, NVD_MAX);
    const nvdDurationMs = Date.now() - nvdStart;

    console.log('[PLATFORM-SCAN] NVD: ' + nvdFindings.length + ' findings in ' + nvdDurationMs + 'ms (' + nvdCandidates.length + ' deps queried)');

    // 6. Combine and deduplicate
    const allFindings = [...osvFindings, ...ghFindings, ...nvdFindings];
    const deduped = deduplicateFindings(allFindings);

    console.log('[PLATFORM-SCAN] ' + deduped.length + ' unique findings after deduplication');

    // 7. Attribute findings to all affected products
    // Track per-product counts for vulnerability_scans rows
    const productCounts = new Map<string, { critical: number; high: number; medium: number; low: number; total: number; orgId: string; productName: string }>();

    // Initialise all products
    for (const pid of allProductIds) {
      // Find orgId from any purl mapping
      let orgId = '';
      let pName = '';
      for (const prods of purlToProducts.values()) {
        const match = prods.find(p => p.productId === pid);
        if (match) { orgId = match.orgId; pName = match.productName; break; }
      }
      productCounts.set(pid, { critical: 0, high: 0, medium: 0, low: 0, total: 0, orgId, productName: pName });
    }

    let totalCritical = 0, totalHigh = 0, totalMedium = 0, totalLow = 0;
    let newFindingsCount = 0;

    for (const finding of deduped) {
      const affectedProducts = purlToProducts.get(finding.dependencyPurl) || [];

      for (const prod of affectedProducts) {
        // Upsert finding for this product
        const upsertResult = await pool.query(
          'INSERT INTO vulnerability_findings ' +
          '(org_id, product_id, platform_scan_run_id, source, source_id, severity, cvss_score, title, description, ' +
          'dependency_name, dependency_version, dependency_ecosystem, dependency_purl, ' +
          'affected_versions, fixed_version, references_url, mitigation) ' +
          'VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17) ' +
          'ON CONFLICT (product_id, source, source_id, dependency_purl) ' +
          'DO UPDATE SET severity = EXCLUDED.severity, cvss_score = EXCLUDED.cvss_score, ' +
          'title = EXCLUDED.title, description = EXCLUDED.description, ' +
          'affected_versions = EXCLUDED.affected_versions, fixed_version = EXCLUDED.fixed_version, ' +
          'references_url = EXCLUDED.references_url, mitigation = EXCLUDED.mitigation, ' +
          'platform_scan_run_id = EXCLUDED.platform_scan_run_id, updated_at = NOW() ' +
          'RETURNING (xmax = 0) AS is_new',
          [prod.orgId, prod.productId, runId, finding.source, finding.sourceId, finding.severity,
           finding.cvssScore, finding.title, finding.description,
           finding.dependencyName, finding.dependencyVersion, finding.dependencyEcosystem,
           finding.dependencyPurl, finding.affectedVersions, finding.fixedVersion,
           finding.referencesUrl, finding.mitigation]
        );

        if (upsertResult.rows[0]?.is_new) {
          newFindingsCount++;
        }

        // Update per-product counts
        const pc = productCounts.get(prod.productId);
        if (pc) {
          pc.total++;
          switch (finding.severity) {
            case 'critical': pc.critical++; break;
            case 'high': pc.high++; break;
            case 'medium': pc.medium++; break;
            case 'low': pc.low++; break;
          }
        }
      }

      // Update global severity counts (once per unique finding)
      switch (finding.severity) {
        case 'critical': totalCritical++; break;
        case 'high': totalHigh++; break;
        case 'medium': totalMedium++; break;
        case 'low': totalLow++; break;
      }
    }

    // 8. Create per-product vulnerability_scans rows
    for (const [productId, counts] of productCounts) {
      if (counts.total === 0 && depList.length > 0) {
        // Product had deps but no findings — still record the scan
      }
      await pool.query(
        'INSERT INTO vulnerability_scans ' +
        '(org_id, product_id, platform_scan_run_id, status, source, findings_count, ' +
        'critical_count, high_count, medium_count, low_count, ' +
        'duration_seconds, started_at, completed_at, triggered_by) ' +
        'VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, NOW(), $13)',
        [counts.orgId, productId, runId, 'completed', 'multi',
         counts.total, counts.critical, counts.high, counts.medium, counts.low,
         ((Date.now() - scanStartTime) / 1000).toFixed(2),
         new Date(scanStartTime).toISOString(),
         triggeredBy]
      );
    }

    // 9. Send targeted notifications
    await sendScanNotifications(runId, deduped, productCounts, purlToProducts, triggeredBy);

    // 10. Update platform_scan_runs with final metrics
    const totalDurationSeconds = (Date.now() - scanStartTime) / 1000;
    await pool.query(
      'UPDATE platform_scan_runs SET ' +
      "status = 'completed', completed_at = NOW(), duration_seconds = $2, " +
      'total_findings = $3, critical_count = $4, high_count = $5, medium_count = $6, low_count = $7, ' +
      'new_findings_count = $8, osv_duration_ms = $9, osv_findings = $10, ' +
      'github_duration_ms = $11, github_findings = $12, nvd_duration_ms = $13, nvd_findings = $14 ' +
      'WHERE id = $1',
      [runId, totalDurationSeconds.toFixed(2), deduped.length,
       totalCritical, totalHigh, totalMedium, totalLow, newFindingsCount,
       osvDurationMs, osvFindings.length, ghDurationMs, ghFindings.length,
       nvdDurationMs, nvdFindings.length]
    );

    console.log('[PLATFORM-SCAN] Completed run ' + runId + ': ' + deduped.length + ' findings (' +
      totalCritical + ' critical, ' + totalHigh + ' high, ' + totalMedium + ' medium, ' + totalLow + ' low) across ' +
      productCount + ' products in ' + totalDurationSeconds.toFixed(2) + 's');

    return { runId, totalFindings: deduped.length };

  } catch (err) {
    const totalDurationSeconds = (Date.now() - scanStartTime) / 1000;
    console.error('[PLATFORM-SCAN] Run ' + runId + ' failed:', err);
    await pool.query(
      "UPDATE platform_scan_runs SET status = 'failed', completed_at = NOW(), " +
      'duration_seconds = $2, error_message = $3 WHERE id = $1',
      [runId, totalDurationSeconds.toFixed(2), (err as Error).message]
    );

    // Notify platform admins of failure
    const admins = await pool.query('SELECT id, org_id FROM users WHERE is_platform_admin = TRUE');
    for (const admin of admins.rows) {
      await createNotification({
        orgId: admin.org_id,
        userId: admin.id,
        type: 'scan_failed',
        severity: 'high',
        title: 'Platform vulnerability scan failed',
        body: (err as Error).message || 'An error occurred during the platform vulnerability scan',
        link: '/admin/vuln-scan',
        metadata: { runId, error: (err as Error).message },
      }).catch(() => {});
    }

    throw err;
  }
}

// --- Targeted stakeholder notifications ---
async function sendScanNotifications(
  runId: string,
  deduped: VulnFinding[],
  productCounts: Map<string, { critical: number; high: number; medium: number; low: number; total: number; orgId: string; productName: string }>,
  purlToProducts: Map<string, ProductRef[]>,
  triggeredBy: string
): Promise<void> {
  // Per-product notifications to stakeholders
  for (const [productId, counts] of productCounts) {
    if (counts.total === 0) continue;

    const worstSeverity = counts.critical > 0 ? 'critical'
      : counts.high > 0 ? 'high'
      : counts.medium > 0 ? 'medium'
      : 'low';

    const parts: string[] = [];
    if (counts.critical > 0) parts.push(counts.critical + ' critical');
    if (counts.high > 0) parts.push(counts.high + ' high');
    if (counts.medium > 0) parts.push(counts.medium + ' medium');
    if (counts.low > 0) parts.push(counts.low + ' low');

    const title = counts.total + ' vulnerabilit' + (counts.total === 1 ? 'y' : 'ies') + ' found in ' + counts.productName;
    const body = 'Platform scan completed: ' + parts.join(', ') + '. Review findings and take action.';
    const link = '/products/' + productId + '?tab=risk-findings';

    // Look up stakeholders for this product
    const stakeholders = await pool.query(
      "SELECT s.role_key, s.name, s.email FROM stakeholders s " +
      "WHERE (s.org_id = $1 AND s.product_id = $2 AND s.role_key = 'security_contact') " +
      "OR (s.org_id = $1 AND s.product_id IS NULL AND s.role_key = 'compliance_officer')",
      [counts.orgId, productId]
    );

    const notifiedUserIds = new Set<string>();

    for (const sh of stakeholders.rows) {
      if (!sh.email) continue;

      // Check if stakeholder is a registered user
      const userResult = await pool.query(
        'SELECT id FROM users WHERE email = $1 AND org_id = $2',
        [sh.email, counts.orgId]
      );

      if (userResult.rows.length > 0) {
        const userId = userResult.rows[0].id;
        if (notifiedUserIds.has(userId)) continue;
        notifiedUserIds.add(userId);

        await createNotification({
          orgId: counts.orgId,
          userId,
          type: 'vulnerability_found',
          severity: worstSeverity as 'critical' | 'high' | 'medium' | 'low',
          title,
          body,
          link,
          metadata: { productId, productName: counts.productName, runId, findingsCount: counts.total },
        });
      }
    }

    // Always send org broadcast as well
    await createNotification({
      orgId: counts.orgId,
      userId: null,
      type: 'vulnerability_found',
      severity: worstSeverity as 'critical' | 'high' | 'medium' | 'low',
      title,
      body,
      link,
      metadata: { productId, productName: counts.productName, runId, findingsCount: counts.total },
    });
  }

  // Platform summary notification to all platform admins
  const totalFindings = deduped.length;
  const productsWithFindings = Array.from(productCounts.values()).filter(c => c.total > 0).length;

  if (totalFindings > 0) {
    const admins = await pool.query('SELECT id, org_id FROM users WHERE is_platform_admin = TRUE');
    for (const admin of admins.rows) {
      await createNotification({
        orgId: admin.org_id,
        userId: admin.id,
        type: 'vulnerability_found',
        severity: 'info',
        title: 'Platform scan complete: ' + totalFindings + ' findings across ' + productsWithFindings + ' products',
        body: 'Scanned ' + Array.from(new Set(Array.from(productCounts.keys()))).length + ' products with ' +
              deduped.length + ' unique vulnerabilities. Triggered by: ' + triggeredBy,
        link: '/admin/vuln-scan',
        metadata: { runId, totalFindings, productsWithFindings },
      });
    }
  }
}
