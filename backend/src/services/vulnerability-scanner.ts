import pool from '../db/pool.js';
import { getDriver } from '../db/neo4j.js';
import { createNotification } from './notifications.js';
import { satisfies, valid } from 'semver';

interface Dependency {
  name: string;
  version: string;
  purl: string;
  ecosystem: string;
  license: string;
}

interface VulnFinding {
  source: string;
  sourceId: string;
  severity: string;
  cvssScore: number | null;
  title: string;
  description: string;
  dependencyName: string;
  dependencyVersion: string;
  dependencyEcosystem: string;
  dependencyPurl: string;
  affectedVersions: string;
  fixedVersion: string;
  referencesUrl: string;
  mitigation: string;
}

interface ProductRef {
  productId: string;
  orgId: string;
  productName: string;
}

// --- Mitigation guidance generator ---
function generateMitigation(finding: Partial<VulnFinding>): string {
  const parts: string[] = [];

  if (finding.fixedVersion) {
    parts.push('Upgrade ' + finding.dependencyName + ' from ' + finding.dependencyVersion + ' to ' + finding.fixedVersion + ' or later.');
  } else {
    parts.push('Check for a patched version of ' + finding.dependencyName + ' (current: ' + finding.dependencyVersion + ').');
  }

  if (finding.severity === 'critical') {
    parts.push('CRITICAL: This vulnerability requires immediate remediation. Consider blocking deployment until resolved.');
  } else if (finding.severity === 'high') {
    parts.push('HIGH priority: Schedule remediation within the current sprint or release cycle.');
  } else if (finding.severity === 'medium') {
    parts.push('MEDIUM priority: Plan remediation in an upcoming release.');
  } else {
    parts.push('LOW priority: Address when convenient or during routine maintenance.');
  }

  if (!finding.fixedVersion) {
    parts.push('If no patch is available: evaluate whether the vulnerable functionality is used in your application. Consider alternative packages or applying a workaround.');
  }

  parts.push('CRA Art. 13(6): Document this vulnerability and remediation steps in your vulnerability handling process.');

  return parts.join(' ');
}

// --- Ecosystem normalisation ---
function normalizeEcosystem(eco: string): string | null {
  const map: Record<string, string> = {
    'npm': 'npm',
    'pip': 'PyPI',
    'pypi': 'PyPI',
    'maven': 'Maven',
    'go': 'Go',
    'nuget': 'NuGet',
    'rust': 'crates.io',
    'crates.io': 'crates.io',
    'composer': 'Packagist',
    'packagist': 'Packagist',
    'rubygems': 'RubyGems',
    'gem': 'RubyGems',
  };
  return map[eco?.toLowerCase()] || null;
}

// --- Version matching ---
function isVersionAffected(
  version: string,
  affectedRanges: any[],
  affectedVersions: string[],
  ecosystem: string
): boolean {
  if (!version) return true; // Conservative: if no version, assume affected

  // Check explicit versions list first
  if (affectedVersions && affectedVersions.length > 0) {
    if (affectedVersions.includes(version)) return true;
  }

  // Check ranges
  if (!affectedRanges || affectedRanges.length === 0) {
    return affectedVersions && affectedVersions.length > 0 ? false : true;
  }

  for (const range of affectedRanges) {
    if (range.type === 'SEMVER') {
      if (isSemverAffected(version, range.events)) return true;
    } else if (range.type === 'ECOSYSTEM') {
      // npm, NuGet, crates.io, RubyGems use semver-compatible versioning
      if (['npm', 'NuGet', 'crates.io', 'RubyGems'].includes(ecosystem)) {
        if (isSemverAffected(version, range.events)) return true;
      } else {
        // For non-semver ecosystems, check explicit versions or be conservative
        if (!affectedVersions || affectedVersions.length === 0) return true;
      }
    }
    // GIT ranges reference commit SHAs — skip for PURL-based matching
  }

  return false;
}

function isSemverAffected(version: string, events: Array<Record<string, string>>): boolean {
  if (!events || events.length === 0) return false;

  const cleanVersion = version.replace(/^v/, '');
  if (!valid(cleanVersion)) return true; // Can't parse, be conservative

  let affected = false;
  for (const event of events) {
    if (event.introduced !== undefined) {
      const intro = event.introduced === '0' ? '0.0.0' : event.introduced.replace(/^v/, '');
      try {
        if (valid(intro) && satisfies(cleanVersion, '>=' + intro)) {
          affected = true;
        } else if (!valid(intro)) {
          affected = true; // Can't parse intro, be conservative
        }
      } catch {
        affected = true;
      }
    }
    if (event.fixed !== undefined && affected) {
      const fix = event.fixed.replace(/^v/, '');
      try {
        if (valid(fix) && satisfies(cleanVersion, '>=' + fix)) {
          affected = false; // Version is at or past the fix
        }
      } catch {
        // Parse error, keep affected state
      }
    }
    if (event.last_affected !== undefined && affected) {
      const la = event.last_affected.replace(/^v/, '');
      try {
        if (valid(la) && !satisfies(cleanVersion, '<=' + la)) {
          affected = false; // Version is past last_affected
        }
      } catch {
        // Parse error, keep affected state
      }
    }
  }

  return affected;
}

// --- Local OSV/GHSA scan (replaces scanOSV + scanGitHub) ---
async function scanLocalOSV(dependencies: Dependency[]): Promise<VulnFinding[]> {
  const findings: VulnFinding[] = [];
  if (dependencies.length === 0) return findings;

  // Group deps by ecosystem for batch queries
  const depsByEcosystem = new Map<string, Dependency[]>();
  for (const dep of dependencies) {
    const eco = normalizeEcosystem(dep.ecosystem);
    if (!eco) continue;
    if (!depsByEcosystem.has(eco)) depsByEcosystem.set(eco, []);
    depsByEcosystem.get(eco)!.push(dep);
  }

  for (const [ecosystem, deps] of depsByEcosystem) {
    const packageNames = deps.map(d => d.name.toLowerCase());
    const depLookup = new Map<string, Dependency>();
    for (const dep of deps) {
      depLookup.set(dep.name.toLowerCase(), dep);
    }

    // Batch query: all advisories matching these packages in this ecosystem
    const advisories = await pool.query(
      'SELECT advisory_id, source, ecosystem, package_name, package_purl, ' +
      'severity, cvss_score, cvss_vector, title, description, ' +
      'affected_ranges, affected_versions, fixed_version, aliases, references_json ' +
      'FROM vuln_db_advisories ' +
      'WHERE ecosystem = $1 AND LOWER(package_name) = ANY($2) AND withdrawn_at IS NULL',
      [ecosystem, packageNames]
    );

    for (const row of advisories.rows) {
      const dep = depLookup.get(row.package_name.toLowerCase());
      if (!dep) continue;

      // Check version ranges
      if (!isVersionAffected(dep.version, row.affected_ranges, row.affected_versions, ecosystem)) {
        continue;
      }

      // Determine source for backward compat
      const source = row.advisory_id.startsWith('GHSA-') ? 'github' : 'osv';

      // Prefer CVE alias as sourceId
      const aliases: string[] = row.aliases || [];
      const cveAlias = aliases.find((a: string) => a.startsWith('CVE-'));
      const sourceId = cveAlias || row.advisory_id;

      const refsArray: Array<{ url: string }> = row.references_json || [];
      const refsStr = refsArray.map(r => r.url).filter(Boolean).join(', ');

      const severity = normaliseSeverity(row.severity || mapCVSStoSeverity(row.cvss_score ? parseFloat(row.cvss_score) : null));

      const finding: VulnFinding = {
        source,
        sourceId,
        severity,
        cvssScore: row.cvss_score ? parseFloat(row.cvss_score) : null,
        title: row.title || sourceId,
        description: (row.description || '').substring(0, 2000),
        dependencyName: dep.name,
        dependencyVersion: dep.version,
        dependencyEcosystem: dep.ecosystem,
        dependencyPurl: dep.purl,
        affectedVersions: formatAffectedRanges(row.affected_ranges),
        fixedVersion: row.fixed_version || '',
        referencesUrl: refsStr,
        mitigation: '',
      };
      finding.mitigation = generateMitigation(finding);
      findings.push(finding);
    }
  }

  console.log('[VULN-SCAN] Local OSV/GHSA: ' + findings.length + ' findings from ' + dependencies.length + ' deps');
  return findings;
}

function formatAffectedRanges(ranges: any[]): string {
  if (!ranges || ranges.length === 0) return '';
  const parts: string[] = [];
  for (const range of ranges) {
    const eventParts: string[] = [];
    for (const event of range.events || []) {
      if (event.introduced) eventParts.push('>= ' + event.introduced);
      if (event.fixed) eventParts.push('< ' + event.fixed);
      if (event.last_affected) eventParts.push('<= ' + event.last_affected);
    }
    if (eventParts.length > 0) parts.push(eventParts.join(', '));
  }
  return parts.join(' | ');
}

// --- Ecosystem to CPE target_sw mapping ---
// Map ecosystems to CPE target_sw values — only specific targets, no wildcards
// Wildcard CPEs (target_sw=*) cause massive false positives (e.g. Adobe Connect vs npm connect)
const ECOSYSTEM_CPE_TARGET: Record<string, string[]> = {
  npm:    ['node.js'],
  pip:    ['python'],
  go:     ['go'],
  cargo:  ['rust'],
  nuget:  ['.net'],
  maven:  ['java'],
  gem:    ['ruby'],
  composer: ['php', 'wordpress'],
};

// Generic CPE product names that cause false positives when matched alone
const GENERIC_CPE_NAMES = new Set([
  'core', 'utils', 'common', 'base', 'config', 'types', 'helpers', 'plugin',
  'cli', 'node', 'runtime', 'api', 'server', 'client', 'parser', 'compiler',
  'generator', 'template', 'code', 'data', 'debug', 'test', 'log', 'file',
  'path', 'url', 'http', 'json', 'xml', 'css', 'html', 'string', 'object',
  'array', 'buffer', 'stream', 'event', 'error', 'query', 'ms', 'os',
  'connect', 'resolve', 'merge', 'glob', 'color', 'colors', 'cookie',
  'agent', 'proxy', 'router', 'body', 'form', 'strip', 'wrap', 'set',
  'get', 'has', 'map', 'find', 'run', 'send', 'raw', 'safe', 'deep',
  'flat', 'once', 'call', 'bind', 'text', 'type', 'is', 'on',
]);

// Normalise an npm package name to CPE product search terms
// e.g. "@babel/traverse" → ["babel_traverse", "babel-traverse"]
//      "express"         → ["express"]
// Does NOT include bare generic names from scoped packages (e.g. "core" from "@babel/core")
function npmNameToCpeProducts(name: string): string[] {
  const products: string[] = [];
  // Strip scope, replace special chars with underscores
  const bare = name.replace(/^@/, '').replace(/\//g, '_').replace(/-/g, '_').toLowerCase();
  products.push(bare);
  // For scoped packages, only add the short name if it's specific enough
  if (name.startsWith('@') && name.includes('/')) {
    const pkgPart = name.split('/')[1].replace(/-/g, '_').toLowerCase();
    if (pkgPart !== bare && !GENERIC_CPE_NAMES.has(pkgPart)) {
      products.push(pkgPart);
    }
  }
  // Also try with hyphens preserved (some CPE vendors use hyphens)
  const withHyphens = name.replace(/^@/, '').replace(/\//g, '-').toLowerCase();
  if (withHyphens !== bare) products.push(withHyphens);
  return [...new Set(products)];
}

// Check if a dependency version falls within a CPE match's version range
// Works with both jsonb CPE objects (camelCase) and flattened index rows (snake_case)
function cpeVersionMatch(depVersion: string, cpeMatch: any): boolean {
  const v = valid(depVersion);
  if (!v) return true; // If we can't parse version, assume vulnerable (conservative)

  const cpeVersion = cpeMatch.version_exact || null;
  const startIncl = cpeMatch.version_start_incl || cpeMatch.versionStartIncluding;
  const startExcl = cpeMatch.version_start_excl || cpeMatch.versionStartExcluding;
  const endIncl = cpeMatch.version_end_incl || cpeMatch.versionEndIncluding;
  const endExcl = cpeMatch.version_end_excl || cpeMatch.versionEndExcluding;

  // If CPE has a specific version (not wildcard) and no ranges, exact match
  if (cpeVersion && cpeVersion !== '*' && !startIncl && !startExcl && !endIncl && !endExcl) {
    const cpeV = valid(cpeVersion);
    return cpeV ? v === cpeV : false;
  }

  // Range checks using semver
  if (startIncl) {
    const sv = valid(startIncl);
    if (sv && satisfies(v, '<' + sv)) return false;
  }
  if (startExcl) {
    const sv = valid(startExcl);
    if (sv && satisfies(v, '<=' + sv)) return false;
  }
  if (endExcl) {
    const sv = valid(endExcl);
    if (sv && satisfies(v, '>=' + sv)) return false;
  }
  if (endIncl) {
    const sv = valid(endIncl);
    if (sv && satisfies(v, '>' + sv)) return false;
  }

  return true;
}

// --- Local NVD scan (CPE index matching) ---
async function scanLocalNVD(dependencies: Dependency[]): Promise<VulnFinding[]> {
  const findings: VulnFinding[] = [];
  if (dependencies.length === 0) return findings;

  // Build lookup: CPE product name -> dependencies
  const productToDeps = new Map<string, Dependency[]>();
  const allProducts: string[] = [];

  for (const dep of dependencies) {
    const products = npmNameToCpeProducts(dep.name);
    for (const p of products) {
      if (!productToDeps.has(p)) {
        productToDeps.set(p, []);
        allProducts.push(p);
      }
      productToDeps.get(p)!.push(dep);
    }
  }

  // Determine target_sw values for the ecosystem
  const targets = ECOSYSTEM_CPE_TARGET[dependencies[0]?.ecosystem] || ['*'];

  // Query the flattened CPE index table in batches - fast indexed lookups
  const BATCH_SIZE = 100;
  for (let i = 0; i < allProducts.length; i += BATCH_SIZE) {
    const batch = allProducts.slice(i, i + BATCH_SIZE);

    try {
      const productPlaceholders = batch.map((_, idx) => '$' + (idx + 1));
      const targetPlaceholders = targets.map((_, idx) => '$' + (batch.length + idx + 1));

      // Fast indexed query on the flattened CPE index
      const cpeResult = await pool.query(
        "SELECT DISTINCT ci.cve_id, ci.product, ci.version_exact, " +
        "ci.version_start_incl, ci.version_start_excl, " +
        "ci.version_end_incl, ci.version_end_excl " +
        "FROM vuln_db_nvd_cpe_index ci " +
        "WHERE ci.product IN (" + productPlaceholders.join(',') + ") " +
        "AND ci.target_sw IN (" + targetPlaceholders.join(',') + ")",
        [...batch, ...targets]
      );

      if (cpeResult.rows.length === 0) continue;

      // Group CPE matches by CVE ID for bulk NVD data fetch
      const cveToCpeMatches = new Map<string, any[]>();
      for (const row of cpeResult.rows) {
        if (!cveToCpeMatches.has(row.cve_id)) cveToCpeMatches.set(row.cve_id, []);
        cveToCpeMatches.get(row.cve_id)!.push(row);
      }

      // Fetch CVE details for matched CVEs
      const cveIds = [...cveToCpeMatches.keys()];
      const cvePlaceholders = cveIds.map((_, idx) => '$' + (idx + 1));
      const nvdResult = await pool.query(
        "SELECT cve_id, description, severity, cvss_score, cvss_vector, " +
        "references_json, affected_versions, fixed_version " +
        "FROM vuln_db_nvd WHERE cve_id IN (" + cvePlaceholders.join(',') + ")",
        cveIds
      );

      const cveData = new Map<string, any>();
      for (const row of nvdResult.rows) cveData.set(row.cve_id, row);

      // Match deps against CPE version ranges
      for (const [cveId, cpeMatches] of cveToCpeMatches) {
        const nvd = cveData.get(cveId);
        if (!nvd) continue;

        for (const cpe of cpeMatches) {
          const matchedDeps = productToDeps.get(cpe.product);
          if (!matchedDeps) continue;

          for (const dep of matchedDeps) {
            if (!cpeVersionMatch(dep.version, cpe)) continue;

            const refsArray: Array<{ url: string }> = nvd.references_json || [];
            const refsStr = refsArray.map((r: any) => r.url).filter(Boolean).join(', ');

            findings.push({
              source: 'nvd',
              sourceId: cveId,
              severity: normaliseSeverity(nvd.severity),
              cvssScore: nvd.cvss_score ? parseFloat(nvd.cvss_score) : null,
              title: cveId + ': ' + (nvd.description || '').substring(0, 120),
              description: (nvd.description || '').substring(0, 2000),
              dependencyName: dep.name,
              dependencyVersion: dep.version,
              dependencyEcosystem: dep.ecosystem,
              dependencyPurl: dep.purl,
              affectedVersions: nvd.affected_versions || '',
              fixedVersion: nvd.fixed_version || cpe.version_end_excl || '',
              referencesUrl: refsStr,
              mitigation: '',
            });
          }
        }
      }
    } catch (err) {
      console.error('[VULN-SCAN] Local NVD CPE batch error:', err);
    }
  }

  // Deduplicate - same CVE + same dep should only appear once
  const seen = new Set<string>();
  const deduped = findings.filter(f => {
    const key = f.sourceId + '|' + f.dependencyPurl;
    if (seen.has(key)) return false;
    seen.add(key);
    return true;
  });

  // Generate mitigations after dedup
  for (const f of deduped) f.mitigation = generateMitigation(f);

  console.log('[VULN-SCAN] Local NVD (CPE): ' + deduped.length + ' findings from ' + dependencies.length + ' deps');
  return deduped;
}

// --- Shared helpers ---
function mapCVSStoSeverity(score: number | undefined | null): string {
  if (!score) return 'medium';
  if (score >= 9.0) return 'critical';
  if (score >= 7.0) return 'high';
  if (score >= 4.0) return 'medium';
  return 'low';
}

// Normalise severity labels across sources (GitHub uses "moderate" instead of "medium")
function normaliseSeverity(sev: string): string {
  const s = (sev || 'medium').toLowerCase();
  if (s === 'moderate') return 'medium';
  if (['critical', 'high', 'medium', 'low'].includes(s)) return s;
  return 'medium';
}

function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}

function deduplicateFindings(findings: VulnFinding[]): VulnFinding[] {
  const seen = new Map<string, VulnFinding>();
  const sourcePriority: Record<string, number> = { 'github': 3, 'osv': 2, 'nvd': 1 };

  for (const finding of findings) {
    const key = finding.sourceId + ':' + finding.dependencyPurl;
    const existing = seen.get(key);

    if (!existing) {
      seen.set(key, finding);
    } else {
      const priority = sourcePriority[finding.source] || 0;
      const existingPriority = sourcePriority[existing.source] || 0;

      if (priority > existingPriority) {
        if (!finding.fixedVersion && existing.fixedVersion) finding.fixedVersion = existing.fixedVersion;
        if (!finding.affectedVersions && existing.affectedVersions) finding.affectedVersions = existing.affectedVersions;
        if (!finding.cvssScore && existing.cvssScore) finding.cvssScore = existing.cvssScore;
        finding.mitigation = generateMitigation(finding);
        seen.set(key, finding);
      } else {
        if (!existing.fixedVersion && finding.fixedVersion) existing.fixedVersion = finding.fixedVersion;
        if (!existing.affectedVersions && finding.affectedVersions) existing.affectedVersions = finding.affectedVersions;
        if (!existing.cvssScore && finding.cvssScore) existing.cvssScore = finding.cvssScore;
        existing.mitigation = generateMitigation(existing);
      }
    }
  }

  return Array.from(seen.values());
}

// --- Findings reconciliation (auto-resolve stale findings) ---
async function reconcileFindings(
  allProductIds: Set<string>,
  purlToProducts: Map<string, ProductRef[]>,
  currentDepsByProduct: Map<string, Set<string>>
): Promise<number> {
  let totalResolved = 0;

  for (const productId of allProductIds) {
    const currentPurls = currentDepsByProduct.get(productId) || new Set();

    // Get all open findings for this product
    const openFindings = await pool.query(
      "SELECT id, dependency_purl, fixed_version, source, source_id FROM vulnerability_findings " +
      "WHERE product_id = $1 AND status = 'open'",
      [productId]
    );

    const resolvedIds: string[] = [];

    for (const finding of openFindings.rows) {
      let shouldResolve = false;

      // 1. Dependency removed from product
      if (!currentPurls.has(finding.dependency_purl)) {
        shouldResolve = true;
      }

      // 2. Check if advisory was withdrawn (OSV/GHSA only)
      if (!shouldResolve && (finding.source === 'osv' || finding.source === 'github')) {
        const withdrawn = await pool.query(
          'SELECT 1 FROM vuln_db_advisories WHERE advisory_id = $1 AND withdrawn_at IS NOT NULL LIMIT 1',
          [finding.source_id]
        );
        if (withdrawn.rows.length > 0) {
          shouldResolve = true;
        }
      }

      if (shouldResolve) {
        resolvedIds.push(finding.id);
      }
    }

    if (resolvedIds.length > 0) {
      await pool.query(
        "UPDATE vulnerability_findings SET status = 'auto_resolved', updated_at = NOW() WHERE id = ANY($1)",
        [resolvedIds]
      );
      totalResolved += resolvedIds.length;
      console.log('[VULN-SCAN] Auto-resolved ' + resolvedIds.length + ' findings for product ' + productId);
    }
  }

  return totalResolved;
}

// =====================================================================
// Platform-wide vulnerability scan
// =====================================================================

export async function runPlatformScan(
  triggeredBy: string,
  triggerType: 'scheduled' | 'manual'
): Promise<{ runId: string; totalFindings: number }> {

  // 1. Create platform scan run record
  const runResult = await pool.query(
    "INSERT INTO platform_scan_runs (triggered_by, trigger_type, status) VALUES ($1, $2, 'running') RETURNING id",
    [triggeredBy, triggerType]
  );
  const runId = runResult.rows[0].id;
  const scanStartTime = Date.now();

  console.log('[PLATFORM-SCAN] Started run ' + runId + ' (triggered by: ' + triggeredBy + ', type: ' + triggerType + ')');

  try {
    // 2. Gather ALL dependencies across ALL products from Neo4j
    const neo4jSession = getDriver().session();
    const uniqueDeps = new Map<string, Dependency>();
    const purlToProducts = new Map<string, ProductRef[]>();
    const allProductIds = new Set<string>();
    const currentDepsByProduct = new Map<string, Set<string>>();

    try {
      const result = await neo4jSession.run(
        'MATCH (o:Organisation)<-[:BELONGS_TO]-(p:Product)-[:DEPENDS_ON]->(d:Dependency) ' +
        'RETURN o.id AS orgId, p.id AS productId, p.name AS productName, ' +
        'd.name AS depName, d.version AS depVersion, d.purl AS depPurl, ' +
        'd.ecosystem AS depEcosystem, d.license AS depLicense'
      );

      for (const record of result.records) {
        const purl = record.get('depPurl') || '';
        const productId = record.get('productId');
        const orgId = record.get('orgId');
        const productName = record.get('productName') || 'Unknown';

        if (!purl) continue;

        allProductIds.add(productId);

        // Track deps per product (for reconciliation)
        if (!currentDepsByProduct.has(productId)) currentDepsByProduct.set(productId, new Set());
        currentDepsByProduct.get(productId)!.add(purl);

        // Deduplicated dependency list
        if (!uniqueDeps.has(purl)) {
          uniqueDeps.set(purl, {
            name: record.get('depName') || '',
            version: record.get('depVersion') || '',
            purl,
            ecosystem: record.get('depEcosystem') || '',
            license: record.get('depLicense') || '',
          });
        }

        // Map purl to products
        if (!purlToProducts.has(purl)) {
          purlToProducts.set(purl, []);
        }
        const existing = purlToProducts.get(purl)!;
        if (!existing.some(p => p.productId === productId)) {
          existing.push({ productId, orgId, productName });
        }
      }
    } finally {
      await neo4jSession.close();
    }

    const depList = Array.from(uniqueDeps.values());
    const productCount = allProductIds.size;

    console.log('[PLATFORM-SCAN] Found ' + depList.length + ' unique dependencies across ' + productCount + ' products');

    // Update run with counts
    await pool.query(
      'UPDATE platform_scan_runs SET total_products = $2, total_unique_dependencies = $3 WHERE id = $1',
      [runId, productCount, depList.length]
    );

    if (depList.length === 0) {
      await pool.query(
        "UPDATE platform_scan_runs SET status = 'completed', completed_at = NOW(), duration_seconds = 0, total_findings = 0 WHERE id = $1",
        [runId]
      );
      console.log('[PLATFORM-SCAN] No dependencies to scan, completing');
      return { runId, totalFindings: 0 };
    }

    // 3. Run local DB scans in parallel (no rate limits!)
    const localDbStart = Date.now();
    const [osvFindings, nvdFindings] = await Promise.all([
      scanLocalOSV(depList),
      scanLocalNVD(depList),
    ]);
    const localDbDurationMs = Date.now() - localDbStart;

    // Split OSV findings by source for backward compat metrics
    const osvOnlyFindings = osvFindings.filter(f => f.source === 'osv');
    const ghsaFindings = osvFindings.filter(f => f.source === 'github');

    console.log('[PLATFORM-SCAN] Local DB scan: ' + osvFindings.length + ' OSV/GHSA findings + ' +
      nvdFindings.length + ' NVD findings in ' + localDbDurationMs + 'ms');

    // 4. Combine and deduplicate
    const allFindings = [...osvFindings, ...nvdFindings];
    const deduped = deduplicateFindings(allFindings);

    console.log('[PLATFORM-SCAN] ' + deduped.length + ' unique findings after deduplication');

    // 5. Attribute findings to all affected products
    const productCounts = new Map<string, { critical: number; high: number; medium: number; low: number; total: number; orgId: string; productName: string }>();

    for (const pid of allProductIds) {
      let orgId = '';
      let pName = '';
      for (const prods of purlToProducts.values()) {
        const match = prods.find(p => p.productId === pid);
        if (match) { orgId = match.orgId; pName = match.productName; break; }
      }
      productCounts.set(pid, { critical: 0, high: 0, medium: 0, low: 0, total: 0, orgId, productName: pName });
    }

    let totalCritical = 0, totalHigh = 0, totalMedium = 0, totalLow = 0;
    let newFindingsCount = 0;

    for (const finding of deduped) {
      const affectedProducts = purlToProducts.get(finding.dependencyPurl) || [];

      for (const prod of affectedProducts) {
        const upsertResult = await pool.query(
          'INSERT INTO vulnerability_findings ' +
          '(org_id, product_id, platform_scan_run_id, source, source_id, severity, cvss_score, title, description, ' +
          'dependency_name, dependency_version, dependency_ecosystem, dependency_purl, ' +
          'affected_versions, fixed_version, references_url, mitigation) ' +
          'VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17) ' +
          'ON CONFLICT (product_id, source, source_id, dependency_purl) ' +
          'DO UPDATE SET severity = EXCLUDED.severity, cvss_score = EXCLUDED.cvss_score, ' +
          'title = EXCLUDED.title, description = EXCLUDED.description, ' +
          'affected_versions = EXCLUDED.affected_versions, fixed_version = EXCLUDED.fixed_version, ' +
          'references_url = EXCLUDED.references_url, mitigation = EXCLUDED.mitigation, ' +
          'platform_scan_run_id = EXCLUDED.platform_scan_run_id, updated_at = NOW() ' +
          'RETURNING (xmax = 0) AS is_new',
          [prod.orgId, prod.productId, runId, finding.source, finding.sourceId, finding.severity,
           finding.cvssScore, finding.title, finding.description,
           finding.dependencyName, finding.dependencyVersion, finding.dependencyEcosystem,
           finding.dependencyPurl, finding.affectedVersions, finding.fixedVersion,
           finding.referencesUrl, finding.mitigation]
        );

        if (upsertResult.rows[0]?.is_new) {
          newFindingsCount++;
        }

        const pc = productCounts.get(prod.productId);
        if (pc) {
          pc.total++;
          switch (finding.severity) {
            case 'critical': pc.critical++; break;
            case 'high': pc.high++; break;
            case 'medium': pc.medium++; break;
            case 'low': pc.low++; break;
          }
        }
      }

      switch (finding.severity) {
        case 'critical': totalCritical++; break;
        case 'high': totalHigh++; break;
        case 'medium': totalMedium++; break;
        case 'low': totalLow++; break;
      }
    }

    // 6. Create per-product vulnerability_scans rows
    for (const [productId, counts] of productCounts) {
      await pool.query(
        'INSERT INTO vulnerability_scans ' +
        '(org_id, product_id, platform_scan_run_id, status, source, findings_count, ' +
        'critical_count, high_count, medium_count, low_count, ' +
        'duration_seconds, started_at, completed_at, triggered_by) ' +
        'VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, NOW(), $13)',
        [counts.orgId, productId, runId, 'completed', 'local_db',
         counts.total, counts.critical, counts.high, counts.medium, counts.low,
         ((Date.now() - scanStartTime) / 1000).toFixed(2),
         new Date(scanStartTime).toISOString(),
         triggeredBy]
      );
    }

    // 7. Reconcile stale findings (auto-resolve removed/upgraded deps)
    const autoResolved = await reconcileFindings(allProductIds, purlToProducts, currentDepsByProduct);
    if (autoResolved > 0) {
      console.log('[PLATFORM-SCAN] Auto-resolved ' + autoResolved + ' stale findings');
    }

    // 8. Send targeted notifications
    await sendScanNotifications(runId, deduped, productCounts, purlToProducts, triggeredBy);

    // 9. Update platform_scan_runs with final metrics
    const totalDurationSeconds = (Date.now() - scanStartTime) / 1000;
    await pool.query(
      'UPDATE platform_scan_runs SET ' +
      "status = 'completed', completed_at = NOW(), duration_seconds = $2, " +
      'total_findings = $3, critical_count = $4, high_count = $5, medium_count = $6, low_count = $7, ' +
      'new_findings_count = $8, ' +
      'local_db_duration_ms = $9, local_db_findings = $10, ' +
      'osv_duration_ms = $9, osv_findings = $11, ' +
      'github_duration_ms = 0, github_findings = $12, ' +
      'nvd_duration_ms = $9, nvd_findings = $13 ' +
      'WHERE id = $1',
      [runId, totalDurationSeconds.toFixed(2), deduped.length,
       totalCritical, totalHigh, totalMedium, totalLow, newFindingsCount,
       localDbDurationMs, osvFindings.length + nvdFindings.length,
       osvOnlyFindings.length, ghsaFindings.length, nvdFindings.length]
    );

    console.log('[PLATFORM-SCAN] Completed run ' + runId + ': ' + deduped.length + ' findings (' +
      totalCritical + ' critical, ' + totalHigh + ' high, ' + totalMedium + ' medium, ' + totalLow + ' low) across ' +
      productCount + ' products in ' + totalDurationSeconds.toFixed(2) + 's' +
      (autoResolved > 0 ? ' (' + autoResolved + ' auto-resolved)' : ''));

    return { runId, totalFindings: deduped.length };

  } catch (err) {
    const totalDurationSeconds = (Date.now() - scanStartTime) / 1000;
    console.error('[PLATFORM-SCAN] Run ' + runId + ' failed:', err);
    await pool.query(
      "UPDATE platform_scan_runs SET status = 'failed', completed_at = NOW(), " +
      'duration_seconds = $2, error_message = $3 WHERE id = $1',
      [runId, totalDurationSeconds.toFixed(2), (err as Error).message]
    );

    const admins = await pool.query('SELECT id, org_id FROM users WHERE is_platform_admin = TRUE');
    for (const admin of admins.rows) {
      await createNotification({
        orgId: admin.org_id,
        userId: admin.id,
        type: 'scan_failed',
        severity: 'high',
        title: 'Platform vulnerability scan failed',
        body: (err as Error).message || 'An error occurred during the platform vulnerability scan',
        link: '/admin/vuln-scan',
        metadata: { runId, error: (err as Error).message },
      }).catch(() => {});
    }

    throw err;
  }
}

// --- Targeted stakeholder notifications ---
async function sendScanNotifications(
  runId: string,
  deduped: VulnFinding[],
  productCounts: Map<string, { critical: number; high: number; medium: number; low: number; total: number; orgId: string; productName: string }>,
  purlToProducts: Map<string, ProductRef[]>,
  triggeredBy: string
): Promise<void> {
  for (const [productId, counts] of productCounts) {
    if (counts.total === 0) continue;

    const worstSeverity = counts.critical > 0 ? 'critical'
      : counts.high > 0 ? 'high'
      : counts.medium > 0 ? 'medium'
      : 'low';

    const parts: string[] = [];
    if (counts.critical > 0) parts.push(counts.critical + ' critical');
    if (counts.high > 0) parts.push(counts.high + ' high');
    if (counts.medium > 0) parts.push(counts.medium + ' medium');
    if (counts.low > 0) parts.push(counts.low + ' low');

    const title = counts.total + ' vulnerabilit' + (counts.total === 1 ? 'y' : 'ies') + ' found in ' + counts.productName;
    const body = 'Platform scan completed: ' + parts.join(', ') + '. Review findings and take action.';
    const link = '/products/' + productId + '?tab=risk-findings';

    const stakeholders = await pool.query(
      "SELECT s.role_key, s.name, s.email FROM stakeholders s " +
      "WHERE (s.org_id = $1 AND s.product_id = $2 AND s.role_key = 'security_contact') " +
      "OR (s.org_id = $1 AND s.product_id IS NULL AND s.role_key = 'compliance_officer')",
      [counts.orgId, productId]
    );

    const notifiedUserIds = new Set<string>();

    for (const sh of stakeholders.rows) {
      if (!sh.email) continue;

      const userResult = await pool.query(
        'SELECT id FROM users WHERE email = $1 AND org_id = $2',
        [sh.email, counts.orgId]
      );

      if (userResult.rows.length > 0) {
        const userId = userResult.rows[0].id;
        if (notifiedUserIds.has(userId)) continue;
        notifiedUserIds.add(userId);

        await createNotification({
          orgId: counts.orgId,
          userId,
          type: 'vulnerability_found',
          severity: worstSeverity as 'critical' | 'high' | 'medium' | 'low',
          title,
          body,
          link,
          metadata: { productId, productName: counts.productName, runId, findingsCount: counts.total },
        });
      }
    }

    await createNotification({
      orgId: counts.orgId,
      userId: null,
      type: 'vulnerability_found',
      severity: worstSeverity as 'critical' | 'high' | 'medium' | 'low',
      title,
      body,
      link,
      metadata: { productId, productName: counts.productName, runId, findingsCount: counts.total },
    });
  }

  // Platform summary notification
  const totalFindings = deduped.length;
  const productsWithFindings = Array.from(productCounts.values()).filter(c => c.total > 0).length;

  if (totalFindings > 0) {
    const admins = await pool.query('SELECT id, org_id FROM users WHERE is_platform_admin = TRUE');
    for (const admin of admins.rows) {
      await createNotification({
        orgId: admin.org_id,
        userId: admin.id,
        type: 'vulnerability_found',
        severity: 'info',
        title: 'Platform scan complete: ' + totalFindings + ' findings across ' + productsWithFindings + ' products',
        body: 'Scanned ' + Array.from(new Set(Array.from(productCounts.keys()))).length + ' products with ' +
              deduped.length + ' unique vulnerabilities. Triggered by: ' + triggeredBy,
        link: '/admin/vuln-scan',
        metadata: { runId, totalFindings, productsWithFindings },
      });
    }
  }
}
