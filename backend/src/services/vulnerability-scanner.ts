import pool from '../db/pool.js';
import { getDriver } from '../db/neo4j.js';
import { decrypt } from '../utils/encryption.js';

interface Dependency {
  name: string;
  version: string;
  purl: string;
  ecosystem: string;
  license: string;
}

interface VulnFinding {
  source: string;
  sourceId: string;
  severity: string;
  cvssScore: number | null;
  title: string;
  description: string;
  dependencyName: string;
  dependencyVersion: string;
  dependencyEcosystem: string;
  dependencyPurl: string;
  affectedVersions: string;
  fixedVersion: string;
  referencesUrl: string;
  mitigation: string;
}

// --- Mitigation guidance generator ---
function generateMitigation(finding: Partial<VulnFinding>): string {
  const parts: string[] = [];

  // Primary action: upgrade if fix available
  if (finding.fixedVersion) {
    parts.push(`Upgrade ${finding.dependencyName} from ${finding.dependencyVersion} to ${finding.fixedVersion} or later.`);
  } else {
    parts.push(`Check for a patched version of ${finding.dependencyName} (current: ${finding.dependencyVersion}).`);
  }

  // Severity-based urgency
  if (finding.severity === 'critical') {
    parts.push('CRITICAL: This vulnerability requires immediate remediation. Consider blocking deployment until resolved.');
  } else if (finding.severity === 'high') {
    parts.push('HIGH priority: Schedule remediation within the current sprint or release cycle.');
  } else if (finding.severity === 'medium') {
    parts.push('MEDIUM priority: Plan remediation in an upcoming release.');
  } else {
    parts.push('LOW priority: Address when convenient or during routine maintenance.');
  }

  // If no fix exists, suggest alternatives
  if (!finding.fixedVersion) {
    parts.push('If no patch is available: evaluate whether the vulnerable functionality is used in your application. Consider alternative packages or applying a workaround.');
  }

  // CRA-specific guidance
  parts.push('CRA Art. 13(6): Document this vulnerability and remediation steps in your vulnerability handling process.');

  return parts.join(' ');
}

// --- OSV.dev batch query ---
async function scanOSV(dependencies: Dependency[]): Promise<VulnFinding[]> {
  const findings: VulnFinding[] = [];

  const validDeps = dependencies.filter(d => d.purl && d.purl.startsWith('pkg:'));
  if (validDeps.length === 0) return findings;

  const batchSize = 1000;
  for (let i = 0; i < validDeps.length; i += batchSize) {
    const batch = validDeps.slice(i, i + batchSize);
    const queries = batch.map(d => ({ package: { purl: d.purl } }));

    try {
      const resp = await fetch('https://api.osv.dev/v1/querybatch', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ queries }),
      });

      if (!resp.ok) {
        console.error(`[VULN-SCAN] OSV batch query failed: ${resp.status}`);
        continue;
      }

      const data = await resp.json() as { results: Array<{ vulns?: Array<any> }> };

      for (let j = 0; j < data.results.length; j++) {
        const result = data.results[j];
        const dep = batch[j];
        if (!result.vulns || result.vulns.length === 0) continue;

        for (const vuln of result.vulns) {
          const severity = mapOSVSeverity(vuln);
          const cvss = extractOSVCVSSScore(vuln);
          const cveId = vuln.aliases?.find((a: string) => a.startsWith('CVE-')) || vuln.id;
          const fixedVer = extractFixedVersion(vuln, dep.ecosystem);
          const refs = (vuln.references || []).map((r: any) => r.url).filter(Boolean);
          const uniqueRefs = [...new Set(refs)].join(', ');

          const finding: VulnFinding = {
            source: 'osv',
            sourceId: cveId || vuln.id,
            severity,
            cvssScore: cvss,
            title: vuln.summary || cveId || vuln.id,
            description: (vuln.details || '').substring(0, 2000),
            dependencyName: dep.name,
            dependencyVersion: dep.version,
            dependencyEcosystem: dep.ecosystem,
            dependencyPurl: dep.purl,
            affectedVersions: formatAffectedVersions(vuln),
            fixedVersion: fixedVer,
            referencesUrl: uniqueRefs,
            mitigation: '',
          };
          finding.mitigation = generateMitigation(finding);
          findings.push(finding);
        }
      }
    } catch (err) {
      console.error('[VULN-SCAN] OSV query error:', err);
    }
  }

  return findings;
}

// --- GitHub Advisory Database ---
async function scanGitHub(dependencies: Dependency[], githubToken: string | null): Promise<VulnFinding[]> {
  const findings: VulnFinding[] = [];
  if (!githubToken) {
    console.log('[VULN-SCAN] No GitHub token available, skipping GitHub advisory scan');
    return findings;
  }

  const ecosystemMap: Record<string, string> = {
    'npm': 'npm', 'pip': 'pip', 'maven': 'maven', 'nuget': 'nuget',
    'rubygems': 'rubygems', 'go': 'go', 'rust': 'crates.io', 'composer': 'composer',
  };

  // Build lookup of our dependency names
  const depsByEcosystem: Record<string, Map<string, Dependency>> = {};
  for (const dep of dependencies) {
    const ghEco = ecosystemMap[dep.ecosystem?.toLowerCase()];
    if (!ghEco) continue;
    if (!depsByEcosystem[ghEco]) depsByEcosystem[ghEco] = new Map();
    depsByEcosystem[ghEco].set(dep.name.toLowerCase(), dep);
  }

  for (const [ecosystem, depMap] of Object.entries(depsByEcosystem)) {
    try {
      // Fetch advisories for this ecosystem
      const url = `https://api.github.com/advisories?ecosystem=${ecosystem}&per_page=100`;
      const resp = await fetch(url, {
        headers: {
          'Authorization': `Bearer ${githubToken}`,
          'Accept': 'application/vnd.github+json',
          'X-GitHub-Api-Version': '2022-11-28',
        },
      });

      if (!resp.ok) {
        console.error(`[VULN-SCAN] GitHub advisory query failed for ${ecosystem}: ${resp.status}`);
        continue;
      }

      const advisories = await resp.json() as Array<any>;

      for (const advisory of advisories) {
        if (!advisory.vulnerabilities) continue;

        for (const vuln of advisory.vulnerabilities) {
          const pkgName = vuln.package?.name?.toLowerCase();
          if (!pkgName) continue;

          const matchedDep = depMap.get(pkgName);
          if (!matchedDep) continue;

          const cveId = advisory.cve_id || advisory.ghsa_id;
          const patchedVersions = vuln.patched_versions || '';

          const finding: VulnFinding = {
            source: 'github',
            sourceId: cveId || advisory.ghsa_id,
            severity: (advisory.severity || 'medium').toLowerCase(),
            cvssScore: advisory.cvss?.score || null,
            title: advisory.summary || advisory.ghsa_id,
            description: (advisory.description || '').substring(0, 2000),
            dependencyName: matchedDep.name,
            dependencyVersion: matchedDep.version,
            dependencyEcosystem: matchedDep.ecosystem,
            dependencyPurl: matchedDep.purl,
            affectedVersions: vuln.vulnerable_version_range || '',
            fixedVersion: patchedVersions,
            referencesUrl: advisory.html_url || '',
            mitigation: '',
          };
          finding.mitigation = generateMitigation(finding);
          findings.push(finding);
        }
      }
    } catch (err) {
      console.error(`[VULN-SCAN] GitHub advisory error for ${ecosystem}:`, err);
    }
  }

  return findings;
}

// --- NVD (NIST) ---
async function scanNVD(dependencies: Dependency[]): Promise<VulnFinding[]> {
  const findings: VulnFinding[] = [];
  const maxQueries = 10;
  const delayMs = 6500;

  const toQuery = dependencies.slice(0, maxQueries);

  for (const dep of toQuery) {
    try {
      const searchName = dep.name.replace(/^@/, '').replace(/\//, ' ');
      const url = `https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=${encodeURIComponent(searchName)}&resultsPerPage=5`;

      const resp = await fetch(url, {
        headers: { 'Accept': 'application/json' },
      });

      if (resp.status === 403 || resp.status === 429) {
        console.log('[VULN-SCAN] NVD rate limit hit, stopping NVD queries');
        break;
      }

      if (!resp.ok) {
        console.error(`[VULN-SCAN] NVD query failed for ${dep.name}: ${resp.status}`);
        await sleep(delayMs);
        continue;
      }

      const data = await resp.json() as { vulnerabilities?: Array<any> };

      if (data.vulnerabilities) {
        for (const item of data.vulnerabilities) {
          const cve = item.cve;
          if (!cve) continue;

          const cvssData = cve.metrics?.cvssMetricV31?.[0]?.cvssData ||
                          cve.metrics?.cvssMetricV30?.[0]?.cvssData ||
                          cve.metrics?.cvssMetricV2?.[0]?.cvssData;

          const severity = cvssData?.baseSeverity?.toLowerCase() ||
                          mapCVSStoSeverity(cvssData?.baseScore);

          const description = cve.descriptions?.find((d: any) => d.lang === 'en')?.value || '';
          const refs = (cve.references || []).map((r: any) => r.url).filter(Boolean);
          const uniqueRefs = [...new Set(refs)].join(', ');

          // Try to extract fix version from references or description
          const fixedVersion = extractFixFromNVD(cve, dep.name);

          const finding: VulnFinding = {
            source: 'nvd',
            sourceId: cve.id,
            severity: severity || 'medium',
            cvssScore: cvssData?.baseScore || null,
            title: `${cve.id}: ${description.substring(0, 120)}`,
            description: description.substring(0, 2000),
            dependencyName: dep.name,
            dependencyVersion: dep.version,
            dependencyEcosystem: dep.ecosystem,
            dependencyPurl: dep.purl,
            affectedVersions: extractNVDAffectedVersions(cve),
            fixedVersion,
            referencesUrl: uniqueRefs,
            mitigation: '',
          };
          finding.mitigation = generateMitigation(finding);
          findings.push(finding);
        }
      }

      await sleep(delayMs);
    } catch (err) {
      console.error(`[VULN-SCAN] NVD error for ${dep.name}:`, err);
    }
  }

  return findings;
}

// --- NVD-specific helpers ---
function extractFixFromNVD(cve: any, depName: string): string {
  // Look through references for release/tag URLs that suggest a fix
  const refs = (cve.references || []).map((r: any) => r.url || '');
  for (const ref of refs) {
    // Match GitHub release tag URLs like /releases/tag/v6.12.3
    const tagMatch = ref.match(/\/releases\/tag\/v?(\d+\.\d+\.\d+[\w.-]*)/);
    if (tagMatch) return tagMatch[1];
  }
  return '';
}

function extractNVDAffectedVersions(cve: any): string {
  const configs = cve.configurations || [];
  const versions: string[] = [];
  for (const config of configs) {
    for (const node of config.nodes || []) {
      for (const match of node.cpeMatch || []) {
        if (match.vulnerable) {
          const parts: string[] = [];
          if (match.versionStartIncluding) parts.push(`>= ${match.versionStartIncluding}`);
          if (match.versionEndExcluding) parts.push(`< ${match.versionEndExcluding}`);
          if (match.versionEndIncluding) parts.push(`<= ${match.versionEndIncluding}`);
          if (parts.length > 0) versions.push(parts.join(' '));
        }
      }
    }
  }
  return versions.join(' | ');
}

// --- Shared helpers ---
function mapOSVSeverity(vuln: any): string {
  const dbSeverity = vuln.database_specific?.severity;
  if (dbSeverity) return dbSeverity.toLowerCase();
  if (vuln.severity && vuln.severity.length > 0) {
    for (const s of vuln.severity) {
      if (s.type === 'CVSS_V3' && s.score) {
        const scoreMatch = s.score.match(/CVSS:3\.\d\/AV:\w\/AC:\w\/PR:\w\/UI:\w\/S:\w\/C:\w\/I:\w\/A:\w/);
        if (scoreMatch) {
          const numScore = extractCVSSNumericScore(s.score);
          if (numScore !== null) return mapCVSStoSeverity(numScore);
        }
      }
    }
  }
  return 'medium';
}

function extractOSVCVSSScore(vuln: any): number | null {
  if (vuln.severity && vuln.severity.length > 0) {
    for (const s of vuln.severity) {
      if (s.type === 'CVSS_V3' && s.score) {
        return extractCVSSNumericScore(s.score);
      }
    }
  }
  return null;
}

function extractCVSSNumericScore(vector: string): number | null {
  // CVSS v3 score calculation is complex — use a rough approximation
  // by counting impact metrics
  if (!vector.startsWith('CVSS:3')) return null;
  const parts = vector.split('/');
  let score = 0;
  for (const part of parts) {
    if (part.startsWith('AV:N')) score += 2;
    else if (part.startsWith('AV:A')) score += 1.5;
    if (part.startsWith('AC:L')) score += 1;
    if (part.startsWith('PR:N')) score += 1;
    if (part.startsWith('UI:N')) score += 0.5;
    if (part.startsWith('C:H')) score += 1.5;
    if (part.startsWith('I:H')) score += 1.5;
    if (part.startsWith('A:H')) score += 1.5;
  }
  return Math.min(Math.round(score * 10) / 10, 10.0);
}

function mapCVSStoSeverity(score: number | undefined | null): string {
  if (!score) return 'medium';
  if (score >= 9.0) return 'critical';
  if (score >= 7.0) return 'high';
  if (score >= 4.0) return 'medium';
  return 'low';
}

function extractFixedVersion(vuln: any, ecosystem: string): string {
  if (!vuln.affected) return '';
  for (const affected of vuln.affected) {
    if (affected.ranges) {
      for (const range of affected.ranges) {
        if (range.events) {
          const fixed = range.events.find((e: any) => e.fixed);
          if (fixed) return fixed.fixed;
        }
      }
    }
    // Also check versions array for 'SPECIFIC' range type
    if (affected.versions && affected.database_specific?.last_known_affected_version_range) {
      // Some OSV entries have this
    }
  }
  return '';
}

function formatAffectedVersions(vuln: any): string {
  if (!vuln.affected) return '';
  const ranges: string[] = [];
  for (const affected of vuln.affected) {
    if (affected.ranges) {
      for (const range of affected.ranges) {
        const parts: string[] = [];
        for (const event of range.events || []) {
          if (event.introduced) parts.push(`>= ${event.introduced}`);
          if (event.fixed) parts.push(`< ${event.fixed}`);
          if (event.last_affected) parts.push(`<= ${event.last_affected}`);
        }
        if (parts.length > 0) ranges.push(parts.join(', '));
      }
    }
  }
  return ranges.join(' | ');
}

function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}

// --- Main scan function ---
export async function scanProductVulnerabilities(
  productId: string,
  orgId: string,
  userId: string
): Promise<{ scanId: string; findingsCount: number }> {
  const scanResult = await pool.query(
    `INSERT INTO vulnerability_scans (org_id, product_id, status, source)
     VALUES ($1, $2, 'running', 'multi')
     RETURNING id`,
    [orgId, productId]
  );
  const scanId = scanResult.rows[0].id;

  try {
    // Get dependencies from Neo4j
    const driver = getDriver();
    const session = driver.session();
    let dependencies: Dependency[] = [];

    try {
      const result = await session.run(
        `MATCH (p:Product {id: $productId})-[:DEPENDS_ON]->(d:Dependency)
         RETURN d.name AS name, d.version AS version, d.purl AS purl,
                d.ecosystem AS ecosystem, d.license AS license`,
        { productId }
      );
      dependencies = result.records.map(r => ({
        name: r.get('name') || '',
        version: r.get('version') || '',
        purl: r.get('purl') || '',
        ecosystem: r.get('ecosystem') || '',
        license: r.get('license') || '',
      }));
    } finally {
      await session.close();
    }

    if (dependencies.length === 0) {
      await pool.query(
        `UPDATE vulnerability_scans SET status = 'completed', completed_at = NOW(), findings_count = 0
         WHERE id = $1`,
        [scanId]
      );
      return { scanId, findingsCount: 0 };
    }

    const scanStartTime = Date.now();
    console.log(`[VULN-SCAN] Scanning ${dependencies.length} dependencies for product ${productId}`);

    // Update scan with dependency count
    await pool.query('UPDATE vulnerability_scans SET dependency_count = $2 WHERE id = $1', [scanId, dependencies.length]);

    // Get GitHub token
    let githubToken: string | null = null;
    try {
      const tokenResult = await pool.query(
        `SELECT gc.access_token_encrypted
         FROM github_connections gc
         JOIN users u ON u.id = gc.user_id
         WHERE u.org_id = $1
         LIMIT 1`,
        [orgId]
      );
      if (tokenResult.rows.length > 0) {
        githubToken = decrypt(tokenResult.rows[0].access_token_encrypted);
      }
    } catch (err) {
      console.error('[VULN-SCAN] Could not get GitHub token:', err);
    }

    // Run OSV + GitHub in parallel with timing
    const osvStart = Date.now();
    const ghStart = Date.now();
    const [osvFindings, ghFindings] = await Promise.all([
      scanOSV(dependencies),
      scanGitHub(dependencies, githubToken),
    ]);
    const osvDurationMs = Date.now() - osvStart;
    const ghDurationMs = Date.now() - ghStart;

    console.log(`[VULN-SCAN] OSV: ${osvFindings.length} findings in ${osvDurationMs}ms, GitHub: ${ghFindings.length} findings in ${ghDurationMs}ms`);

    // NVD: query deps that have findings from other sources + some extra
    const nvdStart = Date.now();
    const depsWithFindings = new Set([...osvFindings, ...ghFindings].map(f => f.dependencyName));
    const nvdCandidates = dependencies.filter(d => depsWithFindings.has(d.name)).slice(0, 10);
    const nvdFindings = await scanNVD(nvdCandidates);
    const nvdDurationMs = Date.now() - nvdStart;

    console.log(`[VULN-SCAN] NVD: ${nvdFindings.length} findings in ${nvdDurationMs}ms`);

    // Combine and deduplicate
    const allFindings = [...osvFindings, ...ghFindings, ...nvdFindings];
    const deduped = deduplicateFindings(allFindings);

    const totalDurationSeconds = (Date.now() - scanStartTime) / 1000;
    console.log(`[VULN-SCAN] Found ${deduped.length} unique findings (OSV: ${osvFindings.length}, GitHub: ${ghFindings.length}, NVD: ${nvdFindings.length}) in ${totalDurationSeconds.toFixed(2)}s`);

    // Upsert findings
    let criticalCount = 0, highCount = 0, mediumCount = 0, lowCount = 0;

    for (const finding of deduped) {
      await pool.query(
        `INSERT INTO vulnerability_findings
         (org_id, product_id, scan_id, source, source_id, severity, cvss_score, title, description,
          dependency_name, dependency_version, dependency_ecosystem, dependency_purl,
          affected_versions, fixed_version, references_url, mitigation)
         VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17)
         ON CONFLICT (product_id, source, source_id, dependency_purl)
         DO UPDATE SET severity = EXCLUDED.severity, cvss_score = EXCLUDED.cvss_score,
           title = EXCLUDED.title, description = EXCLUDED.description,
           affected_versions = EXCLUDED.affected_versions, fixed_version = EXCLUDED.fixed_version,
           references_url = EXCLUDED.references_url, mitigation = EXCLUDED.mitigation,
           scan_id = EXCLUDED.scan_id, updated_at = NOW()`,
        [orgId, productId, scanId, finding.source, finding.sourceId, finding.severity,
         finding.cvssScore, finding.title, finding.description,
         finding.dependencyName, finding.dependencyVersion, finding.dependencyEcosystem,
         finding.dependencyPurl, finding.affectedVersions, finding.fixedVersion,
         finding.referencesUrl, finding.mitigation]
      );

      switch (finding.severity) {
        case 'critical': criticalCount++; break;
        case 'high': highCount++; break;
        case 'medium': mediumCount++; break;
        case 'low': lowCount++; break;
      }
    }

    await pool.query(
      `UPDATE vulnerability_scans
       SET status = 'completed', completed_at = NOW(), findings_count = $2,
           critical_count = $3, high_count = $4, medium_count = $5, low_count = $6,
           duration_seconds = $7, osv_duration_ms = $8, osv_findings = $9,
           github_duration_ms = $10, github_findings = $11,
           nvd_duration_ms = $12, nvd_findings = $13
       WHERE id = $1`,
      [scanId, deduped.length, criticalCount, highCount, mediumCount, lowCount,
       totalDurationSeconds.toFixed(2), osvDurationMs, osvFindings.length,
       ghDurationMs, ghFindings.length, nvdDurationMs, nvdFindings.length]
    );

    return { scanId, findingsCount: deduped.length };

  } catch (err) {
    console.error('[VULN-SCAN] Scan failed:', err);
    await pool.query(
      `UPDATE vulnerability_scans SET status = 'failed', completed_at = NOW(),
       error_message = $2 WHERE id = $1`,
      [scanId, (err as Error).message]
    );
    throw err;
  }
}

function deduplicateFindings(findings: VulnFinding[]): VulnFinding[] {
  const seen = new Map<string, VulnFinding>();
  const sourcePriority: Record<string, number> = { 'github': 3, 'osv': 2, 'nvd': 1 };

  for (const finding of findings) {
    const key = `${finding.sourceId}:${finding.dependencyPurl}`;
    const existing = seen.get(key);

    if (!existing) {
      seen.set(key, finding);
    } else {
      // Merge: keep highest priority source but fill in missing data
      const priority = sourcePriority[finding.source] || 0;
      const existingPriority = sourcePriority[existing.source] || 0;

      if (priority > existingPriority) {
        // New source is higher priority — use it but fill gaps
        if (!finding.fixedVersion && existing.fixedVersion) finding.fixedVersion = existing.fixedVersion;
        if (!finding.affectedVersions && existing.affectedVersions) finding.affectedVersions = existing.affectedVersions;
        if (!finding.cvssScore && existing.cvssScore) finding.cvssScore = existing.cvssScore;
        finding.mitigation = generateMitigation(finding);
        seen.set(key, finding);
      } else {
        // Existing is higher priority — fill its gaps from new
        if (!existing.fixedVersion && finding.fixedVersion) existing.fixedVersion = finding.fixedVersion;
        if (!existing.affectedVersions && finding.affectedVersions) existing.affectedVersions = finding.affectedVersions;
        if (!existing.cvssScore && finding.cvssScore) existing.cvssScore = finding.cvssScore;
        existing.mitigation = generateMitigation(existing);
      }
    }
  }

  return Array.from(seen.values());
}
